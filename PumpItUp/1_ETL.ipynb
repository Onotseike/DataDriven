{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset files\n",
    "    We will be working with the following files:\n",
    "    * Training set values\n",
    "    * Training set labels\n",
    "    * Test set values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values = pd.read_csv(\"./datasets/train_values.csv\")\n",
    "train_labels = pd.read_csv(\"./datasets/train_labels.csv\")\n",
    "\n",
    "test_values = pd.read_csv(\"./datasets/test_values.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Train Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_values)\n",
    "print(\"*\" * 89)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Train Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_labels)\n",
    "print(\"*\" * 89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Test Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_values)\n",
    "print(\"*\" * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Count the number of missing values per column\n",
    "#print(train_values.describe())\n",
    "#print(\"-\" * 89)\n",
    "print(train_values.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of missing values per column\n",
    "#print(test_values.describe())\n",
    "#print(\"-\" * 89)\n",
    "print(test_values.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_labels = list(train_values.columns.values)\n",
    "column_labels.remove(\"id\")\n",
    "column_labels.remove(\"amount_tsh\")\n",
    "column_labels.remove(\"date_recorded\")\n",
    "column_labels.remove(\"gps_height\")\n",
    "column_labels.remove(\"longitude\")\n",
    "column_labels.remove(\"latitude\")\n",
    "column_labels.remove(\"num_private\")\n",
    "column_labels.remove(\"region_code\")\n",
    "column_labels.remove(\"district_code\")\n",
    "column_labels.remove(\"population\")\n",
    "column_labels.remove(\"construction_year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values = test_values.fillna(test_values.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in column_labels:\n",
    "    unique_values = list(set(np.concatenate((train_values[col].unique(), test_values[col].unique()))))\n",
    "    size = len(unique_values)\n",
    "    print(size)\n",
    "    for s in range(size):\n",
    "        if unique_values[s] != \"nan\":\n",
    "            train_values.loc[train_values[col] == unique_values[s], col] = s\n",
    "            test_values.loc[test_values[col] == unique_values[s], col] = s\n",
    "\n",
    "train_values = train_values.fillna(train_values.median())\n",
    "test_values = test_values.fillna(test_values.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values.to_csv(\"./datasets/train.csv\", index=False, header=True)\n",
    "test_values.to_csv(\"./datasets/test.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = list(train_values.columns)\n",
    "print(col_names)\n",
    "print(len(col_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_train_val = train_values.interpolate(method='linear', limit_direction='forward').fillna(\"NODATA\")\n",
    "filled_test_val = test_values.interpolate(method='linear', limit_direction='forward').fillna(\"NODATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filled_train_val.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filled_test_val.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = [col_names[idx] for idx in [0,1,4,6,7,9,13,14,17,18,20,22,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39]]\n",
    "print(selected_cols)\n",
    "print(len(selected_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_train_val = filled_train_val[selected_cols].set_index(\"id\")\n",
    "selected_test_val = filled_test_val[selected_cols].set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_train_val.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_test_val.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_train = selected_train_val\n",
    "for (name,data) in normalize_train.iteritems():\n",
    "    if normalize_train[name].dtypes != np.object:\n",
    "        normalize_train[name] = ((data - data.min())/(data.max() - data.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_test = selected_test_val\n",
    "for(name,data) in normalize_test.iteritems():\n",
    "    if normalize_test[name].dtypes != np.object:\n",
    "        normalize_test[name] = ((data - data.min())/(data.max() - data.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unique = {}\n",
    "for (name, data) in normalize_train.iteritems():\n",
    "    if normalize_train[name].dtypes == np.object:\n",
    "        unique = list(data.unique())\n",
    "        unique.insert(0,\"NODATA\")\n",
    "        unique = list(set(unique))\n",
    "        no = unique.index('NODATA')        \n",
    "        unique[0], unique[no] = unique[no], unique[0]       \n",
    "        train_unique[name] = {unique[idx] : idx for idx in range(len(unique))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_normalize_train = normalize_train.select_dtypes(include=['object']).copy()\n",
    "object_normalize_train.replace(train_unique, inplace=True)\n",
    "\n",
    "object_normalize_test = normalize_test.select_dtypes(include=['object']).copy()\n",
    "object_normalize_test.replace(train_unique, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_train.info(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = normalize_train.select_dtypes(include=['float64']).merge(object_normalize_train, left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = normalize_test.select_dtypes(include=['float64']).merge(object_normalize_test, left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"./datasets/train.csv\", index=True, header=True)\n",
    "test.to_csv(\"./datasets/test.csv\", index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if the ID column of both the formatted train dataset is equal to the id column of the train labels dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"./datasets/train.csv\")[\"id\"].equals(train_labels[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_unique = {\"functional\": 0, \"functional needs repair\" : 1, \"non functional\" : 2 }\n",
    "labels = train_labels[\"status_group\"].copy()\n",
    "for idx, value in labels.iteritems():\n",
    "    labels[idx] = label_unique[value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train = pd.read_csv(\"./datasets/train.csv\")\n",
    "merged_train[\"status_group\"] = train_labels[\"status_group\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.to_csv(\"./datasets/int_labels.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train = pd.read_csv(\"./datasets/train.csv\")\n",
    "merged_train[\"status_group\"] = train_labels[\"status_group\"]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}