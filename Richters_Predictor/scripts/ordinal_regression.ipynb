{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrdinalClassifier:\n",
    "    def __init__(self, classifier : RandomForestClassifier):\n",
    "        self.classifier = classifier\n",
    "        self.classifiers = {}\n",
    "    \n",
    "    def fit(self, input, output):\n",
    "        self.unique_class = np.sort(np.unique(output))\n",
    "\n",
    "        if self.unique_class.shape[0] > 2:\n",
    "            for idx in range(self.unique_class.shape[0] - 1):\n",
    "                binary_output = (output > self.unique_class[idx]).astype(np.uint8)\n",
    "                #print(binary_output)\n",
    "                classifier = clone(self.classifier)\n",
    "                classifier.fit(input, binary_output)\n",
    "                self.classifiers[idx] = classifier\n",
    "    \n",
    "    def predict_proba(self, input):\n",
    "        self.classifiers_predict = { idx:self.classifiers[idx].predict_proba(input) for idx in self.classifiers}\n",
    "        #print(classifiers_predict)\n",
    "        \n",
    "        predicted = []\n",
    "\n",
    "        for idx, idy in enumerate(self.unique_class):\n",
    "            #print(\"IDX, IDY  == \", idx, \"   \", idy)\n",
    "            if idx == 0:\n",
    "                predicted.append(1 - self.classifiers_predict[idy-1][:, 1])\n",
    "            \n",
    "            elif idy-1 in self.classifiers_predict:\n",
    "                predicted.append(self.classifiers_predict[idy - 1 - 1][:, 1] - self.classifiers_predict[idy - 1][:, 1])\n",
    "\n",
    "            else:\n",
    "                predicted.append(self.classifiers_predict[idy - 1 - 1][:, 1])\n",
    "\n",
    "        return np.vstack(predicted).T\n",
    "\n",
    "    def predict(self, input):\n",
    "        return np.argmax(self.predict_proba(input=input), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner:\n",
    "\n",
    "    def __init__(self, train_df : pd.DataFrame, test_df : pd.DataFrame, submission_df : pd.DataFrame, ordinal_classifier : OrdinalClassifier):\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.submission_df = submission_df\n",
    "\n",
    "        self.ordinal_classifier = ordinal_classifier       \n",
    "    \n",
    "\n",
    "    def split_dataset(self):\n",
    "        self.train_input, self.validation_input, self.train_output, self.validation_output = tts(self.train_df.drop(columns=[\"building_id\", \"damage_grade\"]), self.train_df[\"damage_grade\"], test_size=0.3)\n",
    "        return self.train_input, self.validation_input, self.train_output, self.validation_output\n",
    "    \n",
    "\n",
    "    def create_file(self, predicted_output, file_num : str, obj =True):\n",
    "        if predicted_output.shape[0] == self.submission_df.shape[0]:\n",
    "            #print(True)\n",
    "            submission = self.submission_df.copy()\n",
    "            for (idx,data) in submission[\"damage_grade\"].iteritems():\n",
    "                submission[\"damage_grade\"][idx] = predicted_output[idx]    \n",
    "            if obj:\n",
    "                submission.to_csv(\"../datasets/submissions_orc/submission_\" + file_num + \".csv\", index=False, header=True)\n",
    "            else:\n",
    "                submission.to_csv(\"../datasets/submissions_orc/submission_norm_\" + file_num + \".csv\", index=False, header=True)\n",
    "            del submission\n",
    "            gc.collect()\n",
    "\n",
    "\n",
    "    def train_model(self):\n",
    "        dataset = self.split_dataset()\n",
    "\n",
    "        self.ordinal_classifier.fit(dataset[0], dataset[2])\n",
    "        \n",
    "        predicted_output = self.ordinal_classifier.predict(dataset[1])\n",
    "\n",
    "        predicted_output = predicted_output + 1\n",
    "\n",
    "        self.acc_score = accuracy_score(predicted_output, dataset[3])\n",
    "        self.classification_reports = self.create_classification_report(dataset[3], predicted_output)\n",
    "        self.f1_score = self.get_f1_score(dataset[3], predicted_output)\n",
    "\n",
    "        del dataset        \n",
    "        gc.collect()    \n",
    "\n",
    "    def test_model(self, file_num : int,  create_file=True, obj=True):\n",
    "        self.test_df = self.test_df.fillna(self.test_df.median())\n",
    "        predicted_output = self.ordinal_classifier.predict(self.test_df.drop(columns=[\"building_id\"]))\n",
    "        predicted_output = predicted_output + 1\n",
    "        if create_file:\n",
    "            self.create_file(predicted_output, str(file_num), obj=obj)\n",
    "        return predicted_output\n",
    "    \n",
    "    def plot_confusion_matrix(self):\n",
    "        plot_conf_matrix = plot_confusion_matrix(self.ordinal_classifier, self.validation_input, self.validation_output, display_labels=classes, cmap=plt.cm.Blues, normalize='true') \n",
    "        return plot_conf_matrix\n",
    "    \n",
    "    def create_classification_report(self, validation_output, predicted_output):\n",
    "        report = classification_report(validation_output, predicted_output, output_dict=True)   \n",
    "        return pd.DataFrame(report).transpose()\n",
    "    \n",
    "    def get_cross_validation_score(self):\n",
    "        return cross_val_score(self.ordinal_classifier, self.validation_input, self.validation_output, cv=3)\n",
    "    \n",
    "    def get_f1_score(self, validation_output, predicted_output):\n",
    "        return f1_score(y_true=validation_output, y_pred=predicted_output, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Public Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (1, 2, 3)\n",
    "n_estimators = (200, 300)\n",
    "max_depths = (30, 35, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_norm_df = pd.read_csv(\"../datasets/preprocessed/train_normalize.csv\")\n",
    "test_norm_df = pd.read_csv(\"../datasets/preprocessed/test_normalize.csv\")\n",
    "\n",
    "train_obj_df = pd.read_csv(\"../datasets/preprocessed/train_no_object.csv\")\n",
    "test_obj_df = pd.read_csv(\"../datasets/preprocessed/test_no_object.csv\")\n",
    "\n",
    "submission_df = pd.read_csv(\"../datasets/submission_format.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train for No object data then predict test values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score       support\n",
      "1              0.651328  0.478296  0.551559   7487.000000\n",
      "2              0.728899  0.828123  0.775349  44590.000000\n",
      "3              0.722109  0.609217  0.660876  26104.000000\n",
      "accuracy       0.721531  0.721531  0.721531      0.721531\n",
      "macro avg      0.700778  0.638545  0.662595  78181.000000\n",
      "weighted avg   0.719203  0.721531  0.715696  78181.000000\n",
      "******************************************************************************************\n",
      "40 ------ 0.7215308067177447\n",
      "******************************************************************************************\n",
      "              precision    recall  f1-score      support\n",
      "1              0.646027  0.483587  0.553128   7616.00000\n",
      "2              0.725992  0.825559  0.772581  44376.00000\n",
      "3              0.722863  0.607736  0.660319  26189.00000\n",
      "accuracy       0.719280  0.719280  0.719280      0.71928\n",
      "macro avg      0.698294  0.638961  0.662009  78181.00000\n",
      "weighted avg   0.717154  0.719280  0.713597  78181.00000\n",
      "******************************************************************************************\n",
      "50 ------ 0.7192796203681201\n",
      "******************************************************************************************\n",
      "              precision    recall  f1-score       support\n",
      "1              0.647332  0.478370  0.550171   7582.000000\n",
      "2              0.725642  0.825307  0.772272  44398.000000\n",
      "3              0.721628  0.608183  0.660067  26201.000000\n",
      "accuracy       0.718896  0.718896  0.718896      0.718896\n",
      "macro avg      0.698201  0.637287  0.660837  78181.000000\n",
      "weighted avg   0.716702  0.718896  0.713129  78181.000000\n",
      "******************************************************************************************\n",
      "60 ------ 0.7188958954221614\n",
      "******************************************************************************************\n",
      "              precision    recall  f1-score       support\n",
      "1              0.660594  0.481285  0.556861   7534.000000\n",
      "2              0.728059  0.828998  0.775257  44561.000000\n",
      "3              0.722680  0.608181  0.660505  26086.000000\n",
      "accuracy       0.721812  0.721812  0.721812      0.721812\n",
      "macro avg      0.703778  0.639488  0.664208  78181.000000\n",
      "weighted avg   0.719763  0.721812  0.715923  78181.000000\n",
      "******************************************************************************************\n",
      "40 ------ 0.7218122050114478\n",
      "******************************************************************************************\n",
      "              precision    recall  f1-score       support\n",
      "1              0.658028  0.482717  0.556902   7522.000000\n",
      "2              0.728984  0.828479  0.775554  44496.000000\n",
      "3              0.723545  0.611016  0.662536  26163.000000\n",
      "accuracy       0.722439  0.722439  0.722439      0.722439\n",
      "macro avg      0.703519  0.640737  0.664997  78181.000000\n",
      "weighted avg   0.720337  0.722439  0.716696  78181.000000\n",
      "******************************************************************************************\n",
      "50 ------ 0.7224389557565138\n",
      "******************************************************************************************\n",
      "              precision    recall  f1-score       support\n",
      "1              0.660146  0.475883  0.553071   7588.000000\n",
      "2              0.725215  0.826727  0.772651  44329.000000\n",
      "3              0.723001  0.610493  0.662001  26264.000000\n",
      "accuracy       0.720034  0.720034  0.720034      0.720034\n",
      "macro avg      0.702787  0.637701  0.662574  78181.000000\n",
      "weighted avg   0.718156  0.720034  0.714168  78181.000000\n",
      "******************************************************************************************\n",
      "60 ------ 0.7200342794285056\n",
      "******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for estimator in n_estimators:\n",
    "    for depth in max_depths:\n",
    "        ordinal_classifier = OrdinalClassifier(classifier=RandomForestClassifier(max_depth=depth, n_estimators=estimator))\n",
    "        learner = Learner(train_df=train_obj_df, test_df=test_obj_df, submission_df=submission_df, ordinal_classifier=ordinal_classifier)\n",
    "        learner.train_model()\n",
    "\n",
    "        print(learner.classification_reports)\n",
    "        print(\"*\" * 90)\n",
    "        print(estimator, depth, \"------\", learner.f1_score)\n",
    "        print(\"*\" * 90)\n",
    "                \n",
    "        learner.test_model(file_num=depth+estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score       support\n1              0.646097  0.481651  0.551885   7630.000000\n2              0.725226  0.829246  0.773756  44321.000000\n3              0.729452  0.606672  0.662421  26230.000000\naccuracy       0.720648  0.720648  0.720648      0.720648\nmacro avg      0.700258  0.639190  0.662687  78181.000000\nweighted avg   0.718921  0.720648  0.714749  78181.000000\n******************************************************************************************\n200 40 ------ 0.7206482393420396\n******************************************************************************************\n              precision    recall  f1-score       support\n1              0.642175  0.480787  0.549884   7417.000000\n2              0.726005  0.824955  0.772323  44360.000000\n3              0.725137  0.610286  0.662773  26404.000000\naccuracy       0.719804  0.719804  0.719804      0.719804\nmacro avg      0.697772  0.638676  0.661660  78181.000000\nweighted avg   0.717759  0.719804  0.714222  78181.000000\n******************************************************************************************\n200 50 ------ 0.7198040444609304\n******************************************************************************************\n              precision    recall  f1-score       support\n1              0.645092  0.482896  0.552333   7513.000000\n2              0.729889  0.824432  0.774285  44638.000000\n3              0.719022  0.611487  0.660909  26030.000000\naccuracy       0.720712  0.720712  0.720712      0.720712\nmacro avg      0.698001  0.639605  0.662509  78181.000000\nweighted avg   0.718122  0.720712  0.715208  78181.000000\n******************************************************************************************\n200 60 ------ 0.7207121934996995\n******************************************************************************************\n              precision    recall  f1-score       support\n1              0.645190  0.474713  0.546976   7573.000000\n2              0.724939  0.829814  0.773839  44516.000000\n3              0.724565  0.601295  0.657200  26092.000000\naccuracy       0.719152  0.719152  0.719152      0.719152\nmacro avg      0.698231  0.635274  0.659338  78181.000000\nweighted avg   0.717089  0.719152  0.712937  78181.000000\n******************************************************************************************\n400 40 ------ 0.7191517120528006\n******************************************************************************************\n              precision    recall  f1-score       support\n1              0.652628  0.489969  0.559721   7527.000000\n2              0.728141  0.823688  0.772973  44597.000000\n3              0.717993  0.608435  0.658690  26057.000000\naccuracy       0.719817  0.719817  0.719817      0.719817\nmacro avg      0.699587  0.640697  0.663794  78181.000000\nweighted avg   0.717489  0.719817  0.714352  78181.000000\n******************************************************************************************\n400 50 ------ 0.7198168352924622\n******************************************************************************************\n              precision    recall  f1-score       support\n1              0.645856  0.486534  0.554987   7463.000000\n2              0.729146  0.822126  0.772849  44582.000000\n3              0.717522  0.611991  0.660568  26136.000000\naccuracy       0.719842  0.719842  0.719842      0.719842\nmacro avg      0.697508  0.640217  0.662801  78181.000000\nweighted avg   0.717310  0.719842  0.714517  78181.000000\n******************************************************************************************\n400 60 ------ 0.7198424169555263\n******************************************************************************************\n"
    }
   ],
   "source": [
    "for estimator in n_estimators:\n",
    "    for depth in max_depths:\n",
    "        ordinal_classifier = OrdinalClassifier(classifier=RandomForestClassifier(max_depth=depth, n_estimators=estimator))\n",
    "        learner = Learner(train_df=train_norm_df, test_df=test_norm_df, submission_df=submission_df, ordinal_classifier=ordinal_classifier)\n",
    "        learner.train_model()\n",
    "\n",
    "        print(learner.classification_reports)\n",
    "        print(\"*\" * 90)\n",
    "        print(estimator, depth, \"------\", learner.f1_score)\n",
    "        print(\"*\" * 90)\n",
    "        #plot = learner.plot_confusion_matrix()\n",
    "        \n",
    "        learner.test_model(file_num=depth+estimator, obj=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitpytorchsklearncondaa47df100fa654e0284ed04040d3cf106",
   "language": "python",
   "display_name": "Python 3.7.7 64-bit ('PyTorch_SKLearn': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}